# Description: Override file with optimizations for 64GB RAM / 16-core / 1TB NVMe RAID 1
#
# This file automatically applies when running docker-compose commands.
# To use the base config without overrides: docker-compose -f docker-compose.yml up
#
# Hardware context: User has 4x the recommended RAM (64GB vs 16GB recommended)
# Strategy: Scale conservatively at 2-3x defaults, leaving room for OS file cache
# which is critical for database performance on large datasets

services:
  db:
    # PostgreSQL configuration optimized for 64GB RAM / 16-core / NVMe
    command: >-
      postgres
      -c shared_buffers=8GB
      -c effective_cache_size=40GB
      -c maintenance_work_mem=2GB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=500
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=128MB
      -c min_wal_size=2GB
      -c max_wal_size=8GB
      -c max_worker_processes=16
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=16
      -c max_parallel_maintenance_workers=4
      -c shared_preload_libraries='pg_amqp.so,pg_prewarm'
      -c pg_prewarm.autoprewarm=true
      -c pg_prewarm.autoprewarm_interval=300

    # Explanation of key PostgreSQL settings:
    #
    # shared_buffers=8GB (was 2GB, now 4x)
    #   - Main PostgreSQL memory cache for frequently accessed data
    #   - Set to ~12% of total RAM (conservative for large RAM systems)
    #   - Rule: 25% for ≤32GB RAM, 10-15% for >32GB (let OS cache do more)
    #
    # effective_cache_size=40GB
    #   - Tells query planner how much RAM available for caching (Postgres + OS)
    #   - Set to ~62% of total RAM
    #   - Helps planner choose between index scans vs sequential scans
    #
    # maintenance_work_mem=2GB
    #   - Memory for VACUUM, CREATE INDEX, ALTER TABLE operations
    #   - Speeds up index creation and maintenance significantly
    #   - Can be set up to 2GB safely for large databases
    #
    # checkpoint_completion_target=0.9
    #   - Spread checkpoint I/O over 90% of interval
    #   - Reduces I/O spikes that cause query latency
    #
    # wal_buffers=16MB
    #   - Write-Ahead Log buffer (auto-sized to ~1/32 of shared_buffers)
    #   - 16MB is good for high-write workloads
    #
    # default_statistics_target=500
    #   - Statistics collected for query planning (default: 100)
    #   - Higher = better plans for complex queries (MusicBrainz has very complex schema)
    #   - Increases ANALYZE time but improves query performance
    #
    # random_page_cost=1.1 (default: 4.0)
    #   - Cost of random page read vs sequential (assumes spinning disk)
    #   - NVMe is nearly as fast random as sequential, so set close to 1.0
    #   - Makes planner prefer index scans on fast storage
    #
    # effective_io_concurrency=200 (default: 1)
    #   - Expected concurrent disk I/O operations
    #   - NVMe RAID 1 can handle hundreds of concurrent ops
    #   - Enables parallel bitmap heap scans
    #
    # work_mem=128MB (default: 4MB)
    #   - Memory per query operation (sort, hash join, etc.)
    #   - MusicBrainz has complex queries with many JOINs that benefit from more memory
    #   - Formula: (Available RAM * 0.25) / (max_connections * 2-3)
    #   - With 64GB RAM and 100 connections: 128MB is safe and improves sort/join performance
    #
    # min_wal_size=2GB, max_wal_size=8GB (defaults: 80MB, 1GB)
    #   - Controls WAL size and checkpoint frequency
    #   - Larger = fewer checkpoints = less I/O spikes
    #   - With 1TB storage, 8GB is negligible
    #
    # max_worker_processes=16
    #   - Background worker pool (set to CPU core count)
    #
    # max_parallel_workers_per_gather=4 (default: 2)
    #   - Workers per parallel query node
    #   - With 16 cores, 4 workers per query is reasonable
    #   - Speeds up large aggregations and scans
    #
    # max_parallel_workers=16
    #   - Total parallel workers across all queries
    #   - Allows 4 queries to run with 4 workers each, or many with fewer
    #
    # max_parallel_maintenance_workers=4
    #   - Parallel index creation and VACUUM
    #   - Significantly speeds up CREATE INDEX on large tables
    #
    # shared_preload_libraries='pg_amqp.so,pg_prewarm'
    #   - pg_amqp: Required by MusicBrainz for message queue integration
    #   - pg_prewarm: Cache warming extension for loading tables/indexes into memory
    #
    # pg_prewarm.autoprewarm=true
    #   - Automatically saves buffer cache contents on shutdown
    #   - Restores cache on restart (speeds up recovery from restarts)
    #   - Saves to $PGDATA/autoprewarm.blocks file every 5 minutes
    #
    # pg_prewarm.autoprewarm_interval=300
    #   - How often (in seconds) to save cache state
    #   - 300 = 5 minutes (default)
    #   - Lower = more frequent saves but higher I/O overhead

    shm_size: "8GB"
    # ↑ Shared memory must be >= shared_buffers
    # Used for parallel sorts and hash joins
    # Without enough shm, you get "out of shared memory" errors

  musicbrainz:
    # Remove direct port exposure - only accessible via nginx
    ports: !override
      - 99

    # Health check to detect hung workers and auto-restart
    # Checks if the server responds to HTTP requests
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "--max-time", "10", "http://localhost:5000/"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    # ↑ Health check configuration:
    # - test: Curl the root URL with 10s timeout (fails if workers hung)
    # - interval: Check every 30 seconds
    # - timeout: Fail if check takes >15 seconds
    # - retries: 3 consecutive failures = unhealthy
    # - start_period: Wait 2 minutes for initial startup before checking

    environment:
      - MUSICBRAINZ_SERVER_PROCESSES=40
      # ↑ Plackup worker processes (increased from default 10)
      # Each process handles one HTTP request at a time
      # Formula: CPU_cores * 2.5 to 5 (for I/O-bound workloads with lots of RAM)
      # MusicBrainz is I/O-bound (waiting on database queries)
      # With 16 threads and 64GB RAM: 40 workers = 2.5 per thread
      # Each worker ~500MB under load, so 40 × 500MB = 20GB (49GB available)
      # This allows handling more concurrent slow requests without saturation

      - REPLICATION_TYPE=RT_SLAVE
      # ↑ Tells MusicBrainz server this is a mirror, not the main server

  search:
    environment:
      - SOLR_HEAP=12g
      # ↑ Java heap for Solr (increased from 2g to 12g = 6x default)
      # Solr keeps search indexes in Java heap for fast lookups
      # Rule: Set heap to 50-75% of container RAM allocation
      # With 64GB system RAM: 12GB heap leaves plenty for OS file cache

      - LOG4J_FORMAT_MSG_NO_LOOKUPS=true
      # ↑ Security mitigation for Log4Shell vulnerability (CVE-2021-44228)

    mem_swappiness: 0
    # ↑ Never swap Solr memory to disk (changed from 1 to 0)
    # Swapping Java heap is catastrophic for performance:
    # - JVM garbage collector assumes memory is fast
    # - Page faults during GC cause massive pauses (seconds to minutes)
    # - Can cause cascading failures and OOM errors
    # With 64GB RAM, swapping should never happen anyway

  redis:
    image: redis:7-alpine
    # ↑ Updated from redis:3 (released 2015, EOL)
    # Redis 7 benefits:
    # - Better memory efficiency
    # - Improved eviction algorithms
    # - Functions and triggers
    # - Security improvements

    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru --save ""
    # ↑ Redis configuration for session cache:
    #
    # --maxmemory 2gb
    #   - Hard memory limit (prevents unbounded growth)
    #   - 2GB is generous for session storage
    #   - MusicBrainz uses Redis for user sessions and rate limiting
    #
    # --maxmemory-policy allkeys-lru
    #   - When memory full: evict Least Recently Used keys
    #   - Good for pure cache (all keys are cache, none are critical data)
    #   - Alternative "volatile-lru" only evicts keys with TTL set
    #
    # --save ""
    #   - Disable RDB persistence (no disk snapshots)
    #   - Safe because Redis is used as cache, not primary storage
    #   - Sessions stored in Redis are temporary anyway
    #   - Reduces disk I/O and eliminates "BGSAVE" pauses
    #   - If Redis crashes, users just need to log in again (acceptable)

  # ============================================================================
  # HTTPS/SSL Configuration with Nginx
  # ============================================================================
  # Certificates are injected via base64-encoded environment variables

  nginx:
    image: nginx
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./local/config/nginx/nginx.conf.template:/etc/nginx/nginx.conf.template:ro
    environment:
      - MUSICBRAINZ_DOMAIN=${MUSICBRAINZ_DOMAIN:-musicbrainz.local}
      - SSL_CERTIFICATE_BASE64=${SSL_CERTIFICATE_BASE64:-}
      - SSL_CERTIFICATE_KEY_BASE64=${SSL_CERTIFICATE_KEY_BASE64:-}
      # ↑ SSL Certificate and Private Key (base64 encoded)
      # Encode with: cat cert.pem | base64 -w0
    command:
      - /bin/sh
      - -c
      - |
        CERT_DIR="/etc/nginx/ssl"
        mkdir -p "$$CERT_DIR"

        # Write certificates from base64-encoded environment variables
        if [ -n "$$SSL_CERTIFICATE_BASE64" ] && [ -n "$$SSL_CERTIFICATE_KEY_BASE64" ]; then
          echo "Decoding and writing SSL certificate..."
          echo "$$SSL_CERTIFICATE_BASE64" | base64 -d > "$$CERT_DIR/fullchain.pem"
          echo "$$SSL_CERTIFICATE_KEY_BASE64" | base64 -d > "$$CERT_DIR/privkey.pem"
          chmod 600 "$$CERT_DIR/privkey.pem"
          echo "Certificate written successfully"
        else
          echo "WARNING: SSL_CERTIFICATE_BASE64 or SSL_CERTIFICATE_KEY_BASE64 not set"
          echo "Creating self-signed certificate for development..."
          openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
            -keyout "$$CERT_DIR/privkey.pem" \
            -out "$$CERT_DIR/fullchain.pem" \
            -subj "/CN=$$MUSICBRAINZ_DOMAIN" 2>/dev/null
        fi

        # Generate nginx config from template
        envsubst '$$MUSICBRAINZ_DOMAIN' < /etc/nginx/nginx.conf.template > /etc/nginx/nginx.conf

        # Start nginx in foreground
        exec nginx -g 'daemon off;'
    depends_on:
      - musicbrainz
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "10"
